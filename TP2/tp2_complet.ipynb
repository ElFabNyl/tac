{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP2 COMPLET\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/elfabnyl/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yake\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import spacy\n",
    "from collections import defaultdict, Counter\n",
    "from wordcloud import WordCloud\n",
    "from textblob import Blobber\n",
    "from textblob_fr import PatternTagger, PatternAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from IPython.display import Image\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extraction des mots clés relatifs à 1970"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de fichiers pour l'année 1970 : 100\n"
     ]
    }
   ],
   "source": [
    "kw_extractor = yake.KeywordExtractor(lan=\"fr\", top=50)\n",
    "\n",
    "data_path = \"../data/txt/\"\n",
    "files = [f for f in os.listdir(data_path) if f.endswith('.txt') and \"1970\" in f]\n",
    "\n",
    "print(f\"Nombre de fichiers pour l'année 1970 : {len(files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in sorted(files):\n",
    "    with open(os.path.join(data_path, f), 'r', encoding=\"utf-8\") as file:\n",
    "        text = file.read()\n",
    "    \n",
    "    keywords = kw_extractor.extract_keywords(text)\n",
    "    kept = [kw for kw, score in keywords if len(kw.split()) == 2]  \n",
    "    \n",
    "    print(f\"{f} mentions ces mots clés : {', '.join(kept)}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enrichissement de la liste de stopwords et génération d'un nuage de mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actuellement, les stopwords sont : {'puisque', 'furent', 'bien', 'du', 'fussions', 'ils', 'si', 'très', 'soyons', 'seriez', 'après', 'car', 'étiez', 'peut', 'vous', 'lorsque', 'fus', 'avons', 'alors', 'soient', 'auraient', 'eus', 'le', 'toi', 'aurais', 'fûmes', 'sois', 'où', 'eussent', 'depuis', 'me', 'ayants', 'et', 'suis', 'ses', 'soyez', 'eûtes', 'ce', 'soit', 'y', 'eue', 'certain', 'en', 'beaucoup', 'ton', 'j', 'ayez', 'dans', 'aurez', 'serai', 'plus', 'tel', 'fut', 'pas', 'sommes', 'était', 'donc', 'assez', 'sous', 'avec', 'pendant', 'même', 'aies', 'as', 'aviez', 'eusse', 'étantes', 'sur', 'mon', 'ma', 'moins', 'votre', 'elle', 'trois', 'fait', 'het', 'aie', 'qu', 'qui', 'fussent', 'notre', 'aurait', 'toutes', 'comment', 'été', 'encore', 'chaque', 'ayante', 'leurs', 'de', 'fussiez', 'eu', 'au', 'étante', 'étées', 'a', 'avais', 'serions', 'aux', 'aussi', 'se', 'dit', 'quand', 'faire', 'ces', 'fût', 'cependant', 'sont', 'est', 'dont', 'une', 'deux', 'ni', 'sera', 'ou', 'doit', 'l', 'seras', 'étés', 'dire', 'aurons', 'vos', 'aura', 'son', 'ville', 'elles', 'comme', 'avions', 'eux', 't', 'serez', 'ta', 'avaient', 'les', 'trop', 'êtes', 'auront', 'auriez', 'eurent', 'la', 'c', 'à', 'tout', 'autre', 'nos', 'étaient', 'eusses', 'm', 'jusqu', 'des', 'd', 'étions', 'non', 'cet', 'seront', 'ayant', 'sans', 'dem', 'auras', 'étée', 's', 'un', 'tous', 'faut', 'contre', 'moi', 'mais', 'ne', 'ça', 'eussiez', 'van', 'pourquoi', 'aurai', 'sa', 'par ailleur', 'que', 'ainsi', 'serons', 'être', 'aurions', 'serais', 'fusses', 'ont', 'es', 'mes', 'serait', 'eues', 'eussions', 'celle', 'quelque', 'parce que', 'avez', 'par', 'te', 'n', 'eût', 'il', 'aient', 'avoir', 'je', 'étant', 'eut', 'cela', 'ait', 'lui', 'seraient', 'eûmes', 'leur', 'rossel', 'ayons', 'fûtes', 'fusse', 'nous', 'avait', 'pour', 'étais', 'tes', 'tu', 'ayantes', 'ai', 'on', 'entre', 'étants', 'autres', 'cette'}\n"
     ]
    }
   ],
   "source": [
    "sw = set(stopwords.words(\"french\") + [\"les\", \"plus\", \"cette\", \"fait\", \"faire\", \"être\", \"deux\", \"comme\", \"dont\", \"tout\",\n",
    " \"ils\", \"bien\", \"sans\", \"peut\", \"tous\", \"après\", \"ainsi\", \"donc\", \"cet\", \n",
    " \"sous\", \"celle\", \"entre\", \"encore\", \"toutes\", \"pendant\", \"moins\", \"dire\", \n",
    " \"cela\", \"non\", \"faut\", \"trois\", \"aussi\", \"dit\", \"avoir\", \"doit\", \"contre\", \n",
    " \"depuis\", \"autres\", \"van\", \"het\", \"autre\", \"jusqu\", \"ville\", \"rossel\", \"dem\",\n",
    " \"un\", \"une\", \"le\", \"la\", \"et\", \"ou\", \"mais\", \"que\", \"si\", \"je\", \"tu\", \"il\", \"elle\",\n",
    " \"on\", \"nous\", \"vous\", \"ils\", \"elles\", \"ce\", \"ça\", \"y\", \"en\", \"a\", \"de\", \"pour\",\n",
    " \"par\", \"avec\", \"dans\", \"sur\", \"à\", \"du\", \"des\", \"au\", \"aux\", \"son\", \"sa\", \"ses\",\n",
    " \"leur\", \"leurs\", \"mon\", \"ma\", \"mes\", \"notre\", \"nos\", \"votre\", \"vos\", \"très\",\n",
    " \"trop\", \"assez\", \"beaucoup\", \"quelque\", \"certain\", \"chaque\", \"tel\", \"même\",\n",
    " \"pas\", \"ne\", \"ni\", \"car\", \"lorsque\", \"puisque\", \"comme\", \"quand\", \"où\",\n",
    " \"comment\", \"pourquoi\", \"donc\", \"alors\", \"ainsi\", \"cependant\", \"parce que\",\"par ailleur\"])\n",
    "\n",
    "print(\"Actuellement, les stopwords sont :\", sw)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ici je charge le contenu de tous les fichiers de 1970\n",
    "content_list = []\n",
    "for f in files:\n",
    "    with open(os.path.join(data_path, f), 'r', encoding='utf-8') as f:\n",
    "        content_list.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tout le contenu est mis dans un fichier temporaire\n",
    "temp_path = '../data/tmp'\n",
    "if not os.path.exists(temp_path):\n",
    "    os.mkdir(temp_path)\n",
    "\n",
    "with open(os.path.join(temp_path, '1970.txt'), 'w', encoding='utf-8') as f:\n",
    "    f.write(' '.join(content_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ma Fonction de nettoyage\n",
    "def clean_text(year, folder=None):\n",
    "    if folder is None:\n",
    "        input_path = f\"{year}.txt\"\n",
    "        output_path = f\"{year}_clean.txt\"\n",
    "    else:\n",
    "        input_path = f\"{folder}/{year}.txt\"\n",
    "        output_path = f\"{folder}/{year}_clean.txt\"\n",
    "    \n",
    "    output = open(output_path, \"w\", encoding='utf-8')\n",
    "    with open(input_path, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "        words = nltk.wordpunct_tokenize(text)\n",
    "        kept = [w.upper() for w in words if len(w) > 2 and w.isalpha() and w.lower() not in sw]\n",
    "        kept_string = \" \".join(kept)\n",
    "        output.write(kept_string)\n",
    "    return f'Output has been written in {output_path}!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# j'applique la fonction sur le fichier complet de l'année\n",
    "clean_text(1970, folder=temp_path)\n",
    "\n",
    "with open(os.path.join(temp_path, '1970_clean.txt'), 'r', encoding='utf-8') as f:\n",
    "    after = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour le nuage de mots\n",
    "frequencies = Counter(after.split())\n",
    "cloud = WordCloud(width=2000, height=1000, background_color='white').generate_from_frequencies(frequencies)\n",
    "cloud.to_file(os.path.join(temp_path, \"1970.png\"))\n",
    "Image(filename=os.path.join(temp_path, \"1970.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse de phrases arbitraires avec TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = Blobber(pos_tagger=PatternTagger(), analyzer=PatternAnalyzer())\n",
    "\n",
    "# Liste de phrases arbitraires que j'ai choisi \n",
    "phrases = [\n",
    "    \"Le roi Louis-Philippe fut, de tous les souverains du siècle, celui que les assassins politiques menacèrent le plus.\",\n",
    "    \"Jeudi prochain, à 8 heures du soir, M. Joseph Martin donnera, à la Société royale belge de géographie, une conférence sur ses voyages dans la Sibérie orientale.\",\n",
    "    \"Les bruxellois du centre de la ville étaient auparavant obligés, de partir de 9 heures, de porter leurs dépêches à la gare du Nord ou du Midi\",\n",
    "    \"Le plus fort était fait, et l'amoureux capitaine n'avait qu à rejoindre la mariée. Il entra aussi, sans se préoccuper de ce qu'il répondrait si la conciorgc lui demandait oû il allait, mais la conciorgc so tenait ou fond do sa logo et no so dérangea pas pour lo questionner.\",\n",
    "    \"La représentation gala donnée vendredi au Théâtre communal par le Cercle symphonique et dramatique a été très brillante, avec une salle comble et des invités en tenue de soirée\",\n",
    "    \"Le Roi, accompagné de sa cour, a été chaleureusement accueilli par M. Dustin et M. l'échevin Walravens à son arrivée au foyer du théâtre.\",\n",
    "    \"LLes artistes du Cercle ont connu un grand succès, notamment M 11* de Corroy, cantatrice, et M. L. Quecckers, violoniste, qui ont été longuement applaudis.\",\n",
    "    \"Au théâtre de l'Alhambra, un gigantesque arbre de Noël sera planté pour le bonheur des enfants lors de la représentation d'Ali-Baba.\",\n",
    "    \"Le Roi a salué les artistes du Cercle, en soulignant l'importance de leur contribution à la diffusion de la littérature nationale.\",\n",
    "    \"Molenbeek-Saint-Jean. Naissances, déclarations du 21. — Garçons. 2; filles, — Total : 4.\"\n",
    "\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyser les phrases et résumer les résultats\n",
    "results = []\n",
    "\n",
    "for phrase in phrases:\n",
    "    blob = tb(phrase)\n",
    "    polarity, subjectivity = blob.sentiment\n",
    "    polarity_perc = f\"{100*abs(polarity):.0f}\"\n",
    "    subjectivity_perc = f\"{100*subjectivity:.0f}\"\n",
    "    \n",
    "    if polarity > 0:\n",
    "        polarity_str = f\"{polarity_perc}% positive\"\n",
    "    elif polarity < 0:\n",
    "        polarity_str = f\"{polarity_perc}% negative\"\n",
    "    else:\n",
    "        polarity_str = \"neutral\"\n",
    "    \n",
    "    if subjectivity > 0:\n",
    "        subjectivity_str = f\"{subjectivity}% subjective\"\n",
    "    else:\n",
    "        subjectivity_str = \"perfectly objective\"\n",
    "    \n",
    "    results.append((phrase, polarity_str, subjectivity_str))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Résumé des résultats dans un tableau\n",
    "df_results = pd.DataFrame(results, columns=[\"Phrase\", \"Polarité\", \"Subjectivité\"])\n",
    "print(df_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('tac_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "b1932ab1d169b4769d1550e799423b6477588e745f266d79d9004c136c81607e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
